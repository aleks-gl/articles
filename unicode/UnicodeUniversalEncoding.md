# Unicode - универсальная кодировка
Письменность - древнейший способ передачи и сохранения информации, неизменно актуальный и сегодня. Сделаем небольшое обобщение. Письменность – это представление информации с помощью знаков алфавита или в виде текста. В силу того, что текст – это единственный способ сохранения данных, который напрямую ассоциируется с языком как способом общения, записанный текст остался основой для сохранения и передачи информации в цифровом виде. Уточним, что работу с информацией в данном случае мы рассматриваем в аспекте использования цифровых устройств и такие технологии как квантовый компьютер или иные принципы организации вычислительных устройств выходят за рамки данной работы. Независимо от того, в каком формате хранятся данные в хранилищах (базах данных), для пользователя они представляются в виде текста, так же как и ввод информации в большинстве случаев осуществляется посредством текста. Простой, на первый взгляд, процесс преобразования понятной для человека текстовой информации в цифровой вид, которым может оперировать компьютер, оказался нетривиальным. Обработка текста любыми вычислительными устройствами имеет свои особенности в силу того, что символы алфавита – это графические символы, которые не имеют никакого семантического значения для вычислительных устройств. Учитывая также огромное количество всевозможных символов и знаков в разных национальных алфавитах, мы и получаем интересную задачу перевода в цифровой вид (или кодирования) текстовой информации. Собственно способы кодирования текстовой информации мы и рассмотрим далее.  
## Кратко о принципах кодирования текста
Для начала небольшой экскурс в принципы кодирования текста. Данной информацией обладает любой разработчик программного обеспечения, но, тем не менее,  сделаем небольшой обзор общих принципов кодирования текста. Поскольку методы сохранения и отображения графической формы символа выходят за рамки тематики данной статьи, мы рассмотрим только общие принципы преобразования символов в код.  
Определим общее понятие: кодирование текста — это сопоставление символа некоторому коду, которым программное обеспечение может оперировать. Для примера: слово ``charset`` в кодировке ascii представляет собой набор кодов ``63 68 61 72 73 65 74``. Соответственно в таком виде (точнее, данные коды в бинарном виде) текст хранится в простом текстовом файле и именно в таком виде текст может передаваться в виде блока данных в сетевых пакетах. Подразумевается, что каждый символ алфавита и все знаки, используемые в тексте, должны быть закодированы.  
Конечный набор символов алфавита и знаков, сопоставленный с кодами для представления на цифровом уровне, представляет собой набор символов. Общее понятие «набор символов» (или character set) и общие принципы кодирования символов зафиксированы в документе RFC 2978, который описывает общие принципы кодирования символов для использования в рамках сетевого взаимодействия.  
Разные национальные алфавиты соответственно представляют собой разные наборы символов или иными словами — разные кодировки или разные кодовые страницы. Более того, для одного и того же национального алфавита часто создавалось несколько наборов символов.  
Итогом процессов разработки кодовых страниц в разных странах и разными компаниями стало появление множества кодировок.  
## Виды кодировки
На данный момент можно выделить три основных группы кодировок, это:
- совместимые и основанные на **ASCII** (такие как ISO-646, ISO-8859, CP437, CP737, CP8xx, Windows-12xx, KOI-8 и др.);
- совместимые и основанные на **EBCDIC**;
- реализующие стандарт **Unicode** (эти кодировки рассмотрим подробнее далее).  

Перечисление всего списка доступных кодировок – лишняя информация. Это легко можно найти в общедоступных источниках. Кроме того, основная задача данной работы – определение возможностей стандарта Unicode, который постепенно вытесняет использование базовых кодировок (ASCII и EBCDIC).  
Для понимания причин, которые привели к ослаблению позиций первых кодировок, кратко рассмотрим организацию ASCII и EBCDIC. Кодировки, основанные на ASCII, и кодировка EBCDIC используют фиксированный набор символов, закодированных 8-битными кодами, из которых функциональными являются 7 бит. Это означает, что для каждого нового набора символов, к примеру, символов новой локализации, необходимо было создавать новую кодовую страницу. Что в свою очередь приводило к ряду проблем, как:  
- ошибки при декодировании символов, которые возникали при работе различного программного обеспечения и в итоге отображались искаженные (или псевдографические) символы;
- ограниченность набора символов в рамках одной кодовой страницы;
- наличие множества кодовых страниц; 
- дублирование шрифтов;
- проблемы преобразования одной кодовой страницы в другую.  
## Создание Unicode
Трудности при использовании первых кодировок, а также необходимость в обмене информацией, предпочтительно информацией с добавлением расширенного набора символов, привели с созданию универсальной кодировки.  
Стандарт Unicode позволяет хранить наборы символов разных национальных языков и специальных символов, не создавая новых кодировок, а расширяя существующий набор символов. Независимо от того, на какой платформе и какими средствами был создан текст, Unicode позволяет корректно отображать его на любых устройствах. Именно по этой причине развитие сетевого взаимодействия в глобальных масштабах стимулировало использование и развитие Unicode.  
Первая версия Unicode была представлена в 1991 году, и, в отличие от других кодировок, продолжает развиваться. На данный момент главное направление в его развитии - это добавление новых слоев, языков и символов без изменения принципов кодирования.  
На момент написания данной статьи наиболее свежей версией является Unicode 13.0, которая была выпущена в марте 2020 года. В каждой новой версии соответственно добавляется новый набор символов и новые национальные языки, в версии Unicode 13, к примеру, уже содержится 143 859 кодовых позиции, в то время как версия 12 включала 137929 позиций.  
Для заинтересованных более подробную информацию о версиях Unicode и истории его развития можно получить на официальном сайте Unicode или в Википедии, ссылки на данные источники информации приведены в конце статьи.  
## Общие принципы Unicode
Стандарт Unicode был разработан для создания единой универсальной кодировки, которая позволила бы взаимодействовать в мировых масштабах без трудностей, которые возникали при использовании базовых кодировок. Для реализации данной задачи были выработаны фундаментальные принципы, позволяющие достигнуть заданную цель.  
Основы для кодирования, заложенные при разработке стандарта Unicode, включают в себя:  
- Универсальность — стандарт подразумевает единственный, но большой набор символов, которые могут быть использованы в любом национальном языке;
- Эффективность — независимо от формы, стандарт разработан для эффективного доступа к любому символу;
- Символы, а не графические знаки — стандарт разработан для хранения символов, которые имеют семантическое значение, графическое начертание букв оформлено в виде шрифтов;
- Семантика для каждого символа четко определена. База данных Unicode предоставляет машиночитаемые таблицы свойств символов, которые могут быть использованы для различных алгоритмов, требующих семантических знаний о символах (такие как поиск или сортировка);
- Стандарт предоставляет только наборы кодов для простого текста, без форматирования;
- Логический порядок для представления символов в памяти примерно соответствует порядку ввода текста с клавиатуры, это также примерно соответствует фонетическому порядку;
- Стандарт Unicode позволяет избежать дублирования символов. Идентичные символы для разных национальных алфавитов имеют один код;
- Динамическое объединение — стандарт позволяет объединять символы для создания композитного символа;
- Стабильность — кодировка символов остается стабильной независимо от версии стандарта;
- Конвертируемость — в стандарте представлена идентичность символов с различными базовыми кодировками, включая национальные и международные стандарты.  

Описывая общие принципы для кодирования символов в Unicode, стоит отметить организацию пространства кодирования в виде плоскостей. Плоскость в формате Unicode –  это непрерывный диапазон значений для кодовых позиций. Размерность плоскости составляет 65536 позиций (или 2^16). На данный момент существует 17 плоскостей (0-16). Данное количество принято в связи с ограничением количества кодируемых позиций в форме UTF-16, где максимальное значение для кодовой позиции является 0x10FFFF.  
Распределение символов на плоскостях подчиняется определенным правилам, и в настоящий момент принято следующее распределение:
- Плоскость 0 (0000—FFFF): Основная многоязычная плоскость (Basic Multilingual Plane, BMP);
- Плоскость 1 (10000—1FFFF): Дополнительная многоязычная плоскость (Supplementary Multilingual Plane, SMP);
- Плоскость 2 (20000—2FFFF): Дополнительная идеографическая плоскость (Supplementary Ideographic Plane, SIP);
- Плоскость 3 (30000—3FFFF): Третичная идеографическая плоскость (Tertiary Ideographic Plane, TIP);
- Плоскости 4—13 (40000—DFFFF) не используются;
- Плоскость 14 (E0000—EFFFF): Специализированная дополнительная плоскость (Supplementary Special-purpose Plane, SSP);
- Плоскость 15 (F0000—FFFFF) Дополнительная область для частного использования — A (Supplementary Private Use Area-A, SPUA-A);
- Плоскость 16 (100000—10FFFF) Дополнительная область для частного использования — B (Supplementary Private Use Area-B, SPUA-B).  

Поскольку количество символов и языков в стандарте Unicode довольно большое, на данный момент мы определим только то, что основные символы алфавита закодированы в диапазоне основной многоязычной плоскости. За подробной информацией о наборе символов и размещению позиций для разных национальных языков стоит обратиться к документации стандарта, размещенной на официальном сайте Unicode.  
Кроме использования четко определенных диапазонов для размещения символов, стандарт имеет ряд других архитектурных особенностей, но мы рассмотрим только некоторые из них.  
Реализация функций динамического объединения символов в стандарте Unicode использует четыре алгоритма для нормализации текста: *Normalization Form D (NFD), Normalization Form KD (NFKD), Normalization Form C (NFC),* и *Normalization Form KC (NFKC)*. Описание данных алгоритмов приведено в документации, и в рамках общего обзора мы не будем углубляться в их детализацию.  
Среди других возможностей, включенных в стандарт и не столь очевидных при рассмотрении фундаментальных принципов, отметим также специальные символы.  
Специальные символы в стандарте Unicode используются для реализации нескольких возможностей стандарта, в том числе:  
- для контрольных кодов;
- для управления слоями;
- для кодирования знаков, не являющихся символами, и пр.  

Полный набор возможностей и описание использования специальных символов также можно изучить в официальной документации.  
Среди специальных символов хотелось бы выделить флаг, используемый для определения порядка байт (Byte Order Mark или сокращенно BOM). Почему именно этот символ — потому что неверное определение порядка байт в слове приведет к неверной декодировке.  
Как известно, на разных платформах и в сетевых пакетах порядок байт может быть разным (big-endian, или прямой порядок, и little-endian, или обратный порядок). В том числе и строки Unicode могут быть закодированы в словах с разным порядком байт. Данная возможность применима к двум формам Unicode, это UTF-16 и UTF-32. Для некоторых подвидов порядок байт указывается явно, к примеру UTF-16BE или UTF-16LE.В случае отсутствия внешнего указания для определения порядка байт используется метка «BYTE ORDER MARK»(0xFEFF). Согласно принятому порядку метка BOM устанавливается как префикс для строки.
Если первые два октета строки имеют значение  0xFEFF, форма UTF-16 сохранена с использованием прямого порядка байт (big-endian). Если значение первых двух октетов строки равно  0xFFFE, значит строка сохранена с использованием обратного порядка байт (little-endian). Данные коды не являются символами в Unicode, соответственно, наличие данных кодов в начале строки означает указание порядка байт.  
Для всех форм, допускающих определение порядка байт, правило использования данного символа идентично.  
Полный набор возможностей стандарта Unicode выходит за рамки данной работы, поэтому далее рассмотрим концептуально формы кодирования в рамках данного стандарта.  
## Формы Unicode
На данный момент мы имеем три основных формы Unicode, это:  
- **UTF-8**, описан в ISO/IEC 10646 Annex D или RFC 3629;
- **UTF-16**, описан в ISO/IEC 10646  Annex Q или RFC 2781;
- **UTF-32**, также известен как UCS-4 (RFC-5198).  
Кроме того, формы UTF16 и UTF32 имеют подвиды: UTF-16BE, UTF-16LE, UTF-32BE, UTF-32LE. Как можно понять из аббревиатуры — подвиды определяют порядок байт. Определение порядка байт мы уже рассмотрели ранее. Соответственно принципы кодирования остаются в данном случае неизменными, изменяется только порядок байт для хранения кода.  
Кроме стандартных форм, в документах RFC описаны такие формы как UTF-7, UTF-9 и UTF-18. Но мы их не будем рассматривать, поскольку они не имеют статуса стандартов и представлены в документах «для информации».  
### UTF-32
Форма UTF-32 является самой простой формой кодирования символов, в сущности, это представление номера символа в виде слова фиксированной длины в 32 бита. Из-за своего формата UTF-32 получила наименьшее распространение. Данная форма кодирования позволяет хранить полный набор символов и получать доступ к любому символу за фиксированное время, но при этом значительно увеличивает объем данных.  
Алгоритмы кодирования символов и декодирования для данной формы элементарны, поскольку, как уже сказано, в данной форме код содержит номер символа.  
Использование данного формата менее распространено, чем использование других форм, поэтому подробнее рассмотрим наиболее часто используемые формы Unicode.
### UTF-16
Одна из наиболее распространенных форм кодирования Unicode.  
Форма UTF-16 имеет переменную длину слова для кодирования символа. Символ может быть представлен как одним 16 битным словом, так и парой 16 битных слов.  
Среди особенностей формы UTF-16 можно выделить следующие:  
- форма оптимизирована для представления символов в базовой многоязычной плоскости (Basic Multilingual Plane — BMP);
- для кодирования дополнительных символов в UTF-16 используются два 16-битных слова (или суррогатные пары);
- форма UTF-16 может быть предпочтительной формой кодирования в случаях необходимости соблюдения баланса между эффективным доступом к символам и экономичным использованием пространства;
- данная форма исторически была первой формой стандарта Unicode;
- для данной формы необходимы алгоритмы специальной бинарной сортировки, так как порядок кодов представленных в форме UTF-16 не совпадает с общим порядком кодов в Unicode (в отличие от UTF-32).  

*Кодирование символов в форме UTF-16 происходит по следующим правилам:*  
- Коды символов меньше чем 0x10000 (диапазон 0x0000 — 0xFFFF), исключая указанный ниже диапазон значений для суррогатных пар, представляются одним 16 битным словом;
- Коды символов между 0x10000 и 0x10FFFF представляются как пара 16 битных слов. В данном случае символ кодируется 16 битным значением в диапазоне 0xD800 — 0xDBFF, следующим за 16 битным значением в диапазоне 0xDC00 — 0xDFFF;
- Значения кодов свыше 0x10FFFF не могут быть использованы в данной форме;
- Значения в диапазоне 0xD800 — 0xDFFF зарезервированы и не могут быть использованы для кодирования символов, данный диапазон используется для создания так называемых суррогатных пар.  

Рассмотрим алгоритмы кодирования и декодирования символов. Так как процесс кодирования и декодирования в UTF-16 немного сложнее подобных алгоритмов для UTF-8, то в целях соблюдения достоверности информации, просто рассмотрим алгоритмы, описанные в официальной документации для стандарта.  

Обобщенно ***алгоритм кодирования*** символа в форме UTF-16 можно представить в виде шагов, описанных далее (обозначим номер символа через U). 
1. Если номер символа *U<0x10000*, закодировать символ как 16-битовое целое число без знака и завершить работу.
2. Определим *U’= U - 0x10000*. Поскольку U меньше или равно 0x10FFFF, U’должно быть меньше или равно 0xFFFFF. То есть U’может быть представлен в 20 битах.
3. Инициализировать два 16-разрядных целых числа без знака, W1 и W2, значениями 0xD800 и 0xDC00 соответственно. Каждое из этих целых чисел имеет 10 свободных битов для кодирования символьного значения, всего 20 бит.
4. Назначить 10 старших битов 20-битного U’ 10 младшим битам W1 и 10 младших битов U’ 10 младшим битам W2. Завершить работу.  
*Шаги 2, 3 и 4 в виде слов можно представить следующим образом:*  
>U’ = yyyyyyyyyyxxxxxxxxxx
>W1 = 110110yyyyyyyyyy
>W2 = 110111xxxxxxxxxx  

Далее, для понимания алгоритма, используемого для ***декодирования символа*** сделаем следующие предположения:  
- Пусть W1 будет 16-битным целым числом в последовательности целых чисел, представляющих текст. 
- Пусть W2 будет (возможным) следующим целым числом после W1.  

*Для декодирования одного символа из UTF-16 в значение символа ISO 10646 выполняем действия в следующем порядке.*  
1. Если *W1<0xD800* или *W1>0xDFFF*, символьное значение U является значением W1. Завершить работу.
2. Если W1 находится вне диапазона 0xD800  и 0xDBFF - значит последовательность ошибочна, и с помощью W1 нельзя получить действительный символ. Завершить работу.
3. Если нет W2 (то есть последовательность заканчивается на W1) или если W2 не находится между 0xDC00 и 0xDFFF, последовательность является ошибочной. Завершить работу.
4. Создайте 20-битовое целое число без знака U ’, взяв 10 младших битов W1 как его 10 старших битов и 10 младших битов W2 как его 10 младших битов.
5. Добавить 0x10000 к U’ для получения значения символа U. Завершить работу.  

### UTF-8
Форма UTF-8 является наиболее компактной формой стандарта Unicode. Для кодирования символов в данной форме используются слова переменной длины. Именно благодаря своей компактности данная форма получила наибольшее распространение.  
Форма UTF-8 обладает следующими особенностями:  
- данная форма ориентирована на использование 8-битного кода, что является преимуществом перед другими формами в тех случаях, когда необходима совместимость с программным обеспечением, изначально ориентированным на использование кодов ASCII;
- для кодирования в форме UTF-8 используются слова переменной длины, содержащие 8 битные кодовые единицы (октеты или байты);
- для символов латиницы UTF-8 идентична кодовым позициям ASCII (0x00..0x7F);
- в общем случае UTF-8 более компактна, чем другие формы Unicode;
- благодаря совместимости с ASCII данная форма является предпочтительной для использования в языках разметки для Web ( к примеру, HTML), в сетевых пакетах или в текстовых документах;
- самоорганизация — структура данной формы обладает свойством самоорганизации в тех случаях, где требуется обработка 8-битных символов;
- так же как и UTF-16, данная форма требует дополнительных алгоритмов бинарной сортировки в случаях, когда необходимо отсортировать символы.  

Для кодирования в форме UTF-8 используется следующее соотношение кодовых позиций и количества октетов. Принцип кодирования представлен в формате:  
>``диапазон-номеров-символов`` = ``шаблоны-октетов``  

>``0000 0000-0000 007F`` = ``0xxxxxxx``  
>``0000 0080-0000 07FF`` = ``110xxxxx 10xxxxxx``  
>``0000 0800-0000 FFFF`` = ``1110xxxx 10xxxxxx 10xxxxxx``  
>``0001 0000-0010 FFFF`` = ``11110xxx 10xxxxxx 10xxxxxx 10xxxxxx``  

*Кодирование одного символа по форме UTF-8 выполняется в следующем порядке:*  
1. Определяется количество необходимых для кодирования октет на основании номера символа;
2. Для октетов устанавливаются биты высших порядков в соответствии с указанными диапазонами;
3. Заполняются биты младших порядков, определяющие код символа.  

*Для декодирования символа в форме UTF-8 необходимо выполнить действия в соответствии со следующим порядком:*  
1. Инициализируйте двоичное число, установив все биты в 0 (количество разрядов до 21 бит).
2. Определите, какие биты кодируют номер символа, исходя из количества октетов в последовательности (биты, отмеченные x в диапазоне, указанном выше).
3. Распределите биты из последовательности в двоичное число, сначала – младшие биты из последнего октета последовательности, и переходите влево до тех пор, пока не останется x битов. Двоичное число теперь равно номеру символа.  

Мы кратко рассмотрели некоторые принципы, используемые при реализации стандарта Unicode и основные формы, реализующие данный стандарт кодировки текста. Официальные документы, описывающие данный стандарт, находятся в свободном доступе и при необходимости уточнения информации о Unicode и его формах рекомендуется обратиться именно к ним.  

## Источники информации
Дополнительную информацию о стандарте Unicode можно получить из следующих источников (включая, но не ограничиваясь):  
1. [Официальный сайт стандарта Unicode](http://www.unicode.org);
2. [Internet Engineering Task Force, документация для стандартов сетевого взаимодействия](https://tools.ietf.org);
3. [Информация о Unicode на Википедии](https://en.wikipedia.org/wiki/Unicode);
4. [Организация плоскостей в Unicode](https://en.wikipedia.org/wiki/Plane_(Unicode));
3. RFC 3629 -UTF-8, a transformation format of ISO 10646;
4. RFC 2781 - UTF-16, an encoding of ISO 10646;
5. RFC 5198 - Unicode Format for Network Interchange.
